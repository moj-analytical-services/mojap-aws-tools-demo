{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "from pyarrow import fs, parquet as pq\n",
    "from arrow_pd_parser.parse import (\n",
    "    pa_read_json_to_pandas,\n",
    "    pa_read_csv_to_pandas,\n",
    "    pa_read_json,\n",
    ")\n",
    "from mojap_metadata import Metadata\n",
    "from mojap_metadata.converters.glue_converter import GlueConverter\n",
    "from mojap_metadata.converters.arrow_converter import ArrowConverter\n",
    "# from dataengineeringutils3 import s3\n",
    "import os\n",
    "import boto3\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Create a test folder to work from (need access to `alpha-everyone`)\n",
    "2. Move that single dataset to S3\n",
    "3. Define the datas metadata using our Metadata class\n",
    "4. Read that data back from S3 using pd_arrow ensuring it conforms to our metadata\n",
    "5. Write the data to S3 into a database folder creating a csv table, jsonl table and parquet table (using awswrangler)\n",
    "6. Create the Table DDLs using the glueConverter and awswrangler\n",
    "7. Use aws wrangler to query each table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Add some key parameters probably the only thing you will need to change is your foldername. Second cell does some clean up using `awswrangler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"isichei\" # GH username\n",
    "region = \"eu-west-1\"\n",
    "bucketname = \"alpha-everyone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting objs\n"
     ]
    }
   ],
   "source": [
    "db_name = f\"aws_example_{foldername}\"\n",
    "db_base_path = f\"s3://{bucketname}/{foldername}/database\"\n",
    "s3_base_path = f\"s3://{bucketname}/{foldername}/\"\n",
    "if wr.s3.list_objects(s3_base_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(s3_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Upload a dataset to S3\n",
    "\n",
    "Using `boto3`. There are many ways to do each of these. Hopefully this tutorial gives you a mix of how to do ones that we trust the most or have simple functions that others a re missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "with open(\"data/init-data.csv\", \"rb\") as f:\n",
    "    s3_client.upload_fileobj(f, bucketname, os.path.join(foldername, \"init-data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141592653589</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                     NaN           1            1  1900-01-01   \n",
       "3              malcovitch         NaN  10000000000  1900-01-01   \n",
       "4              malcovitch           1          NaN  1900-01-01   \n",
       "\n",
       "          datetime_col boolean_col float_col      double_col decimal_col  \n",
       "0  1900-01-01 00:00:00        TRUE  0.123456     0.123456789      12.345  \n",
       "1  2018-01-01 23:59:59       FALSE  3.141592  3.141592653589      12.345  \n",
       "2  1900-01-01 00:00:00        TRUE  0.123456     0.123456789      12.345  \n",
       "3  1900-01-01 00:00:00        TRUE  0.123456     0.123456789      12.345  \n",
       "4  1900-01-01 00:00:00        TRUE  0.123456     0.123456789      12.345  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at the data we just uploaded in S3 note we are reading the local version\n",
    "# pd.read_json(\"data/init-data.jsonl\", lines=True, dtype=str).head()\n",
    "pd.read_csv(\"data/init-data.csv\", dtype=str).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the metadata\n",
    "\n",
    "Create the metadata for the data using `mojap-metadata`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Define the metadata\n",
    "meta_dict = {\n",
    "    \"name\": \"test\",\n",
    "    \"description\": \"Some test data of different types\",\n",
    "    \"file_format\": \"jsonl\",\n",
    "    \"columns\":[\n",
    "        {\n",
    "            \"name\": \"character_col\",\n",
    "             \"type\": \"string\",\n",
    "            \"description\": \"This col has a tricky comma that messes with the serdes (parser). You'll see how we account for this later.\"\n",
    "        },\n",
    "        {\"name\": \"int_col\", \"type\": \"int32\"},\n",
    "        {\"name\": \"long_col\", \"type\": \"int64\"},\n",
    "        {\"name\": \"date_col\", \"type\": \"date64\"},\n",
    "        {\"name\": \"datetime_col\", \"type\": \"timestamp(s)\"},\n",
    "        {\"name\": \"boolean_col\", \"type\": \"bool_\"},\n",
    "        {\"name\": \"float_col\", \"type\": \"float32\"},\n",
    "        {\"name\": \"double_col\", \"type\": \"float64\"},\n",
    "        {\"name\": \"decimal_col\", \"type\": \"decimal128(5,3)\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "meta = Metadata.from_dict(meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conform the data to pandas\n",
    "\n",
    "Generate an arrow schema from our metadata (TODO) and then use that to ensure conformance with pandas (using `arrow_pd_parser`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character_col     string\n",
      "int_col            Int64\n",
      "long_col           Int64\n",
      "date_col          object\n",
      "datetime_col      object\n",
      "boolean_col      boolean\n",
      "float_col        float32\n",
      "double_col       float64\n",
      "decimal_col       object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                                   1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "          datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1  2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_data_s3_path = os.path.join(bucketname, foldername, \"init-data.csv\")\n",
    "\n",
    "# Use the Arrow Converter to get a pyarrow schema\n",
    "ac = ArrowConverter()\n",
    "arrow_schema = ac.generate_from_meta(meta)\n",
    "\n",
    "# Read the data in from S3 this time\n",
    "s3 = fs.S3FileSystem(region='eu-west-1')\n",
    "with s3.open_input_stream(init_data_s3_path) as f:\n",
    "    df = pa_read_csv_to_pandas(f, schema=arrow_schema)\n",
    "\n",
    "print(df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write the data to a database\n",
    "\n",
    "Can do this multiple ways so going to do it multiple ways.\n",
    "\n",
    "- (a) Going to write the data to a table using `awswrangler`\n",
    "- (b) Will write the data directly to S3 and use mojap-metadata and boto3 to create the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'aws_example_isichei' already exists\n"
     ]
    }
   ],
   "source": [
    "# For both gonna need to do some setup\n",
    "database_path = os.path.join(bucketname, foldername, \"database\")\n",
    "\n",
    "databases = wr.catalog.databases()\n",
    "if db_name not in databases.values:\n",
    "    wr.catalog.create_database(db_name)\n",
    "    print(f\"Database '{db_name}' already exists\")\n",
    "else:\n",
    "    print(f\"Database '{db_name}' already exists\")\n",
    "    \n",
    "for t in [\"csv_wr\", \"csv_gc\", \"csv_header\", \"csv_open\", \"jsonl_hive\", \"jsonl_openx\", \"parquet_table\"]:\n",
    "    wr.catalog.delete_table_if_exists(database=db_name, table=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's do (a)\n",
    "df_copy = df.copy() # wrangler castsa the col datatypes so gotta be careful as it changes df\n",
    "table_path = f\"s3://{database_path}/csv_wr\"\n",
    "wr.s3.to_csv(\n",
    "    df=df_copy,\n",
    "    path=table_path,\n",
    "    dataset=True,\n",
    "    index=False,\n",
    "    database=db_name,\n",
    "    table='csv_wr',\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.csv_wr\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checkout the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_col': 'string',\n",
       " 'int_col': 'bigint',\n",
       " 'long_col': 'bigint',\n",
       " 'date_col': 'date',\n",
       " 'datetime_col': 'timestamp',\n",
       " 'boolean_col': 'boolean',\n",
       " 'float_col': 'float',\n",
       " 'double_col': 'double',\n",
       " 'decimal_col': 'decimal(5,3)'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.get_table_types(database=db_name, table=\"csv_wr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the types here have been inferred by `awswranger` because we've lost some information between the conversion between arrow -> pandas (e.g. no decimal type in pandas). `awswrangler` is correctly and safely converting your pandas types to glue types to ensure they can be read safely in glue. We can use our metadata and converter to get the column types we want. So let's do that as well...\n",
    "\n",
    "> This didn't work but leaving in here. Might work one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just want columns\n",
    "# gc = GlueConverter()\n",
    "# columns, partitions = gc.convert_columns(meta)\n",
    "# columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get it into the data format needed for awswrangler\n",
    "# dtypes = {}\n",
    "# for c in columns:\n",
    "#     dtypes[c[\"Name\"]] = c[\"Type\"].lower()\n",
    "\n",
    "# wr.s3.to_csv(\n",
    "#     df=df,\n",
    "#     path=table_path,\n",
    "#     dataset=True,\n",
    "#     index=False,\n",
    "#     database=db_name,\n",
    "#     table='csv_wr',\n",
    "#     mode=\"overwrite\",\n",
    "#     dtype=dtypes\n",
    "# )\n",
    "# wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.csv_wr\", database=db_name, ctas_approach=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5(b)\n",
    "\n",
    "So let's move on to using our converter to be exact about the datatypes (let's say we want to try and conform to their origin (as defined in the metadata). Let's write the data somewhere else to compare specifying a glue schema specific to our metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://alpha-everyone/isichei/database/csv_gc/csv_gc.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how we have to write out our CSV to work with the lazy hive schema\n",
    "# wrangler does this under the hood\n",
    "# Also worth noting that this is an aweful way to write CSVs do not use (quoting=csv.QUOTE_NONE) these parameters for any other CSV reader like R or Python!\n",
    "table_path = f\"s3://{database_path}/csv_gc\"\n",
    "wr.s3.to_csv(df, f\"{table_path}/csv_gc.csv\", index=False, header=False, escapechar=\"\\\\\", quoting=csv.QUOTE_NONE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatabaseName': 'aws_example_isichei',\n",
       " 'TableInput': {'Name': 'csv_gc',\n",
       "  'Description': 'Some test data of different types',\n",
       "  'Owner': 'owner',\n",
       "  'Retention': 0,\n",
       "  'StorageDescriptor': {'Columns': [{'Name': 'character_col',\n",
       "     'Type': 'string',\n",
       "     'Comment': \"This col has a tricky comma that messes with the serdes (parser). You'll see how we account for this later.\"},\n",
       "    {'Name': 'int_col', 'Type': 'int'},\n",
       "    {'Name': 'long_col', 'Type': 'bigint'},\n",
       "    {'Name': 'date_col', 'Type': 'date'},\n",
       "    {'Name': 'datetime_col', 'Type': 'timestamp'},\n",
       "    {'Name': 'boolean_col', 'Type': 'boolean'},\n",
       "    {'Name': 'float_col', 'Type': 'float'},\n",
       "    {'Name': 'double_col', 'Type': 'double'},\n",
       "    {'Name': 'decimal_col', 'Type': 'decimal(5,3)'}],\n",
       "   'Location': 's3://alpha-everyone/isichei/database/csv_gc',\n",
       "   'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',\n",
       "   'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',\n",
       "   'Compressed': False,\n",
       "   'NumberOfBuckets': -1,\n",
       "   'SerdeInfo': {'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',\n",
       "    'Parameters': {'field.delim': ',', 'escape.delim': '\\\\'}},\n",
       "   'BucketColumns': [],\n",
       "   'SortColumns': [],\n",
       "   'Parameters': {},\n",
       "   'StoredAsSubDirectories': False},\n",
       "  'PartitionKeys': [],\n",
       "  'TableType': 'EXTERNAL_TABLE',\n",
       "  'Parameters': {'classification': 'csv'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a glue converter and convert our metadata to the GlueAPI specs\n",
    "gc = GlueConverter()\n",
    "meta.file_format = \"csv\"\n",
    "meta.name = \"csv_gc\"\n",
    "\n",
    "boto_dict = gc.generate_from_meta(meta, database_name=db_name, table_location=table_path)\n",
    "boto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table already deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '9e7e004e-37ac-48ef-9cf8-647be54ae58c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 18 Dec 2020 17:00:04 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '9e7e004e-37ac-48ef-9cf8-647be54ae58c'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_client = boto3.client(\"glue\")\n",
    "\n",
    "try:\n",
    "    _ = glue_client.delete_table(\n",
    "        DatabaseName=db_name,\n",
    "        Name=\"csv_gc\"\n",
    "    )\n",
    "except glue_client.exceptions.EntityNotFoundException:\n",
    "    print(\"table already deleted\")\n",
    "\n",
    "glue_client.create_table(**boto_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You'll see we get the same resulted output but we get more exact column types.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.csv_gc\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_col': 'string',\n",
       " 'int_col': 'int',\n",
       " 'long_col': 'bigint',\n",
       " 'date_col': 'date',\n",
       " 'datetime_col': 'timestamp',\n",
       " 'boolean_col': 'boolean',\n",
       " 'float_col': 'float',\n",
       " 'double_col': 'double',\n",
       " 'decimal_col': 'decimal(5,3)'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.get_table_types(database=db_name, table=\"csv_gc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Let's make hella tables with the glueConverter\n",
    "\n",
    "We'll create the following:\n",
    "- CSV with header\n",
    "- CSV openSerde aweful for dates (requires UNIX epochs)\n",
    "- Jsonl (with Hive serde)\n",
    "- Jsonl (with Openx serde)\n",
    "- Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV with header\n",
    "\n",
    "We are actually going to do two things. We are going to specify the seperator as a pipe and write with header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.name = \"csv_header\"\n",
    "meta.file_format = \"csv\"\n",
    "\n",
    "# let's use the same glueConverter\n",
    "gc.options.csv.sep = \"|\"\n",
    "gc.options.csv.skip_header = True\n",
    "gc.options.default_db_name = db_name # set db name so we don't have to set it everytime\n",
    "gc.options.default_db_base_path = f\"s3://{database_path}/\" # set db name so we don't have to set it everytime\n",
    "full_table_path = f\"s3://{database_path}/{meta.name}/{meta.name}.csv\"\n",
    "wr.s3.to_csv(\n",
    "    df,\n",
    "    full_table_path,\n",
    "    index=False,\n",
    "    header=gc.options.csv.skip_header,\n",
    "    escapechar=gc.options.csv.escape_char,\n",
    "    sep=gc.options.csv.sep,\n",
    "    quoting=csv.QUOTE_NONE\n",
    ") # note header=True and sep=\"|\" escapechar is the same as defailt options for converter are \"\\\\\"\n",
    "\n",
    "spec = gc.generate_from_meta(meta)\n",
    "glue_client.create_table(**spec)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta.name}\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV with openSerde\n",
    "\n",
    "We can use a different serde (aka parser) for CSVs. The pros of this parser means that having commas in the character cols work when you write out CSVs like a normal person (quoted values). However, the con here is that it requires you to write out dates and timestamps are based on unix timesstamps. [More on this con](https://stackoverflow.com/questions/52564194/athena-unable-to-parse-date-using-opencsvserde). The TLDR is that dates should be integer days from 1 January 1970 and timestamps should an integer in milliseconds that have elapsed since Midnight 1 January 1970.\n",
    "\n",
    "> This actually fails will also fail unless your data is not NULL - so just avoid openCSV to be honest. More on this null value error: https://aws.amazon.com/premiumsupport/knowledge-center/athena-hive-bad-data-error-csv/\n",
    "So in this example we treat everything but the date and datetimes (which I also fill as 0 just to demonstrate the date types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141592653589</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123456789</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col boolean_col float_col      double_col  decimal_col  \n",
       "0 1900-01-01 00:00:00        True  0.123456     0.123456789       12.345  \n",
       "1 2018-01-01 23:59:59       False  3.141592  3.141592653589       12.345  \n",
       "2 1900-01-01 00:00:00        True  0.123456     0.123456789       12.345  \n",
       "3 1900-01-01 00:00:00        True  0.123456     0.123456789       12.345  \n",
       "4 1900-01-01 00:00:00        True  0.123456     0.123456789       12.345  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_open_csv = Metadata.from_dict(meta_dict)\n",
    "meta_open_csv.name = \"csv_open\"\n",
    "meta_open_csv.file_format = \"csv\"\n",
    "\n",
    "# Do unix conversion\n",
    "df_unix = df.copy()\n",
    "\n",
    "epoch = datetime.datetime.utcfromtimestamp(0)\n",
    "\n",
    "df_unix.datetime_col = df_unix.datetime_col.apply(lambda x: 0 if pd.isna(x) else int((x - epoch).total_seconds() * 1000.0))\n",
    "df_unix.date_col = df_unix.date_col.apply(lambda x: 0 if pd.isna(x) else (x -  datetime.date(1970, 1, 1)).days)\n",
    "\n",
    "# ALSO Cant do decimal\n",
    "for c in meta_open_csv.columns:\n",
    "    if c[\"type\"].startswith(\"decimal\"):\n",
    "        c[\"type\"] = \"float64\"\n",
    "    elif not c[\"name\"].startswith(\"date\"):\n",
    "        c[\"type\"] = \"string\"\n",
    "\n",
    "# let's use the same glueConverter\n",
    "gc.options.set_csv_serde(\"open\") # openCSVSerde\n",
    "gc.options.csv.sep = \",\"\n",
    "gc.options.csv.skip_header = False\n",
    "\n",
    "full_table_path = f\"s3://{database_path}/{meta_open_csv.name}/{meta_open_csv.name}.csv\"\n",
    "wr.s3.to_csv(\n",
    "    df_unix,\n",
    "    full_table_path,\n",
    "    index=False,\n",
    "    header=gc.options.csv.skip_header,\n",
    "    sep=gc.options.csv.sep\n",
    ") # note we are using quotes again and a comma sep!\n",
    "\n",
    "spec = gc.generate_from_meta(meta_open_csv)\n",
    "glue_client.create_table(**spec)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta_open_csv.name}\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝ What a palaver - don't do this unless you definitely want this serde because you hate yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jsonl with Hive Serde\n",
    "\n",
    "JSONL files whoop whoop. Hive serde is the default for the glue-converter. Pandas writer is still not quite there for jsonl so you should cast your dates and datetimes yourself into the appropriate ISO format. Also worth noting that currently awswrangler doesn't have an option to add a pandas table to glue for jsonl types (it only supports CSV and parquet). Most likely this will change in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast dates and timestamps to str\n",
    "df_json = df.copy()\n",
    "df_json.date_col = df_json.date_col.apply(lambda x: pd.NA if pd.isna(x) else str(x)).astype(\"string\")\n",
    "df_json.datetime_col = df_json.datetime_col.apply(lambda x: pd.NA if pd.isna(x) else str(x)).astype(\"string\")\n",
    "\n",
    "meta.name = \"jsonl_hive\"\n",
    "meta.file_format = \"jsonl\" # can also write json\n",
    "\n",
    "gc.options.set_json_serde(\"hive\")\n",
    "# let's use the same glueConverter\n",
    "full_table_path = f\"s3://{database_path}/{meta.name}/{meta.name}.jsonl\"\n",
    "wr.s3.to_json(\n",
    "    df_json,\n",
    "    full_table_path,\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ") # note header=True and sep=\"|\" escapechar is the same as defailt options for converter are \"\\\\\"\n",
    "\n",
    "spec = gc.generate_from_meta(meta)\n",
    "glue_client.create_table(**spec)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta.name}\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_col': 'string',\n",
       " 'int_col': 'int',\n",
       " 'long_col': 'bigint',\n",
       " 'date_col': 'date',\n",
       " 'datetime_col': 'timestamp',\n",
       " 'boolean_col': 'boolean',\n",
       " 'float_col': 'float',\n",
       " 'double_col': 'double',\n",
       " 'decimal_col': 'decimal(5,3)'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.get_table_types(database=db_name, table=meta.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jsonl with Openx Serde\n",
    "\n",
    "Now the openx serde. Differences between this and the Hive one can be [found here](https://docs.aws.amazon.com/athena/latest/ug/json-serde.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.name = \"jsonl_openx\"\n",
    "meta.file_format = \"jsonl\" # can also write json\n",
    "\n",
    "gc.options.set_json_serde(\"openx\")\n",
    "# let's use the same glueConverter\n",
    "full_table_path = f\"s3://{database_path}/{meta.name}/{meta.name}.jsonl\"\n",
    "wr.s3.to_json(\n",
    "    df_json,\n",
    "    full_table_path,\n",
    "    orient=\"records\",\n",
    "    lines=True\n",
    ") # note header=True and sep=\"|\" escapechar is the same as defailt options for converter are \"\\\\\"\n",
    "\n",
    "spec = gc.generate_from_meta(meta)\n",
    "glue_client.create_table(**spec)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta.name}\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_col': 'string',\n",
       " 'int_col': 'int',\n",
       " 'long_col': 'bigint',\n",
       " 'date_col': 'date',\n",
       " 'datetime_col': 'timestamp',\n",
       " 'boolean_col': 'boolean',\n",
       " 'float_col': 'float',\n",
       " 'double_col': 'double',\n",
       " 'decimal_col': 'decimal(5,3)'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.get_table_types(database=db_name, table=meta.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet\n",
    "\n",
    "Finally! This is the easiest dataset to work with because it has metadata built into the data (that does mean you cannot eye ball it with a text editor but who cares). Strongly recommend using this type because it works well with arrow and glue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our meta changes again\n",
    "meta.name = \"parquet_table\"\n",
    "meta.file_format = \"parquet\" # can also write json\n",
    "\n",
    "full_table_path = f\"s3://{database_path}/{meta.name}/{meta.name}.snappy.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now instead of writing to S3 using wrangler we are going to use arrow instead. This allows us to be super specific about our metadata conformance which is why we are all here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            character_col     int_col     long_col    date_col  \\\n",
       "0              malcovitch           1   2147483648  1900-01-01   \n",
       "1  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                    <NA>           1            1  1900-01-01   \n",
       "3              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4              malcovitch           1         <NA>  1900-01-01   \n",
       "\n",
       "         datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataframe to an arrow table and then cast to our specific metadata then write to S3\n",
    "table = pa.Table.from_pandas(df)\n",
    "table = table.cast(arrow_schema)\n",
    "\n",
    "# Write the data to S3 and then generate the glue table as normal\n",
    "s3 = fs.S3FileSystem(region='eu-west-1')\n",
    "with s3.open_output_stream(full_table_path.replace(\"s3://\",\"\")) as f:\n",
    "    pq.write_table(table, f)\n",
    "\n",
    "spec = gc.generate_from_meta(meta)\n",
    "glue_client.create_table(**spec)\n",
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta.name}\", database=db_name, ctas_approach=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character_col': 'string',\n",
       " 'int_col': 'int',\n",
       " 'long_col': 'bigint',\n",
       " 'date_col': 'date',\n",
       " 'datetime_col': 'timestamp',\n",
       " 'boolean_col': 'boolean',\n",
       " 'float_col': 'float',\n",
       " 'double_col': 'double',\n",
       " 'decimal_col': 'decimal(5,3)'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.catalog.get_table_types(database=db_name, table=meta.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Side note using `pd_arrow_parser` to enforce conformance on our databases\n",
    "\n",
    "What is useful about enforcing data conformance is imagine we have a table in our database (lets use `parquet_table` in our database). We produce the table in our database from a CSV extract given to us by some external data supply. There is an update on the data export from our friendly data sender and now we get data as a `jsonl` file. Using `arrow_pd_parser` we can ensure conformance A -> B data formats to ensure updates to our database 👊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our new data is jsonl\n",
    "# # We could just read it directly input pandas but we don't actually need to we can \n",
    "# # just go jsonl -> arrow -> parquet still ensuring metadata conformance\n",
    "arrow_table = pa_read_json(\"data/init-data.jsonl\", schema=arrow_schema)\n",
    "new_data_s3_path = f\"{database_path}/{meta.name}/{meta.name}_new.snappy.parquet\"\n",
    "\n",
    "with s3.open_output_stream(new_data_s3_path) as f:\n",
    "    pq.write_table(arrow_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata schema for the database is already defined and as we haven't changed the datatypes we don't need to do anything. The new data can now be queried via Athena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>long_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>datetime_col</th>\n",
       "      <th>boolean_col</th>\n",
       "      <th>float_col</th>\n",
       "      <th>double_col</th>\n",
       "      <th>decimal_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483648</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>malcovitch, malcovitch</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 23:59:59</td>\n",
       "      <td>False</td>\n",
       "      <td>3.141592</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>None</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>malcovitch</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             character_col     int_col     long_col    date_col  \\\n",
       "0               malcovitch           1   2147483648  1900-01-01   \n",
       "1   malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "2                     <NA>           1            1  1900-01-01   \n",
       "3               malcovitch        <NA>  10000000000  1900-01-01   \n",
       "4               malcovitch           1         <NA>  1900-01-01   \n",
       "5               malcovitch           1  10000000000        None   \n",
       "6               malcovitch           1  10000000000  1900-01-01   \n",
       "7               malcovitch           1  10000000000  1900-01-01   \n",
       "8               malcovitch           1  10000000000  1900-01-01   \n",
       "9               malcovitch           1  10000000000  1900-01-01   \n",
       "10              malcovitch           1   2147483648  1900-01-01   \n",
       "11  malcovitch, malcovitch  2147483647  10000000000  2018-01-01   \n",
       "12                    <NA>           1            1  1900-01-01   \n",
       "13              malcovitch        <NA>  10000000000  1900-01-01   \n",
       "14              malcovitch           1         <NA>  1900-01-01   \n",
       "15              malcovitch           1  10000000000        None   \n",
       "16              malcovitch           1  10000000000  1900-01-01   \n",
       "17              malcovitch           1  10000000000  1900-01-01   \n",
       "18              malcovitch           1  10000000000  1900-01-01   \n",
       "19              malcovitch           1  10000000000  1900-01-01   \n",
       "\n",
       "          datetime_col  boolean_col  float_col  double_col decimal_col  \n",
       "0  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "1  2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "2  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "3  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "4  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "5  1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "6                  NaT         True   0.123456    0.123457      12.345  \n",
       "7  1900-01-01 00:00:00        False   0.123456    0.123457      12.345  \n",
       "8  1900-01-01 00:00:00         True        NaN    0.123457      12.345  \n",
       "9  1900-01-01 00:00:00         True   0.123456         NaN      12.345  \n",
       "10 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "11 2018-01-01 23:59:59        False   3.141592    3.141593      12.345  \n",
       "12 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "13 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "14 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "15 1900-01-01 00:00:00         True   0.123456    0.123457      12.345  \n",
       "16                 NaT         True   0.123456    0.123457      12.345  \n",
       "17 1900-01-01 00:00:00        False   0.123456    0.123457      12.345  \n",
       "18 1900-01-01 00:00:00         True        NaN    0.123457      12.345  \n",
       "19 1900-01-01 00:00:00         True   0.123456         NaN      12.345  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.athena.read_sql_query(f\"SELECT * FROM {db_name}.{meta.name}\", database=db_name, ctas_approach=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
