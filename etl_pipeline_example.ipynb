{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_base_path = 's3://mojap-land/open_data/postcodes_example/'\n",
    "raw_hist_base_path = 's3://mojap-raw-hist/open_data/postcodes_example/'\n",
    "api_get = \"https://api.postcodes.io/random/postcodes\"\n",
    "job_bucket = \"alpha-curated-postcodes-example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sRFkUY6K3CfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'postcode': 'TR1 9XL', 'quality': 5, 'eastings': 182961, 'northings': 43918, 'country': 'England', 'nhs_ha': 'South West', 'longitude': -5.046154, 'latitude': 50.25527, 'european_electoral_region': 'South West', 'primary_care_trust': 'Cornwall and Isles of Scilly', 'region': 'South West', 'lsoa': 'Cornwall 044A', 'msoa': 'Cornwall 044', 'incode': '9XL', 'outcode': 'TR1', 'parliamentary_constituency': 'Truro and Falmouth', 'admin_district': 'Cornwall', 'parish': 'Truro', 'admin_county': None, 'admin_ward': 'Truro Boscawen & Redannick', 'ced': None, 'ccg': 'NHS Kernow', 'nuts': 'Cornwall and Isles of Scilly', 'codes_admin_district': 'E06000052', 'codes_admin_county': 'E99999999', 'codes_admin_ward': 'E05013354', 'codes_parish': 'E04011600', 'codes_parliamentary_constituency': 'E14001003', 'codes_ccg': 'E38000089', 'codes_ccg_id': '11N', 'codes_ced': 'E99999999', 'codes_nuts': 'TLK30', 'codes_lsoa': 'E01018807', 'codes_msoa': 'E02003910', 'codes_lau2': 'E06000052', 'index': 0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Lil' function to take the api response and put into a tabular format\n",
    "def unpack_data(data):\n",
    "    new_dict = {}\n",
    "    row = data['result']\n",
    "    for c in row:\n",
    "        if c != 'codes':\n",
    "            new_dict[c] = row[c]\n",
    "    for c in row[\"codes\"]:\n",
    "        new_dict[\"codes_\" + c] = row[\"codes\"][c]\n",
    "    return new_dict\n",
    "\n",
    "# Get the run timestamp of this script - use it as the file partition (note that I remove milliseconds)\n",
    "run_timestamp = int(datetime.now().timestamp())\n",
    "# Request the API 1000 times\n",
    "data = []\n",
    "for i in range(0,10):\n",
    "    f = urlopen(api_get)\n",
    "    api_out = f.readlines()[0]\n",
    "    row = json.loads(api_out)\n",
    "    \n",
    "    new_row = unpack_data(row)\n",
    "    new_row['index'] = i\n",
    "    data.append(new_row)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "from gluejobutils.s3 import (\n",
    "    s3_path_to_bucket_key,\n",
    "    s3_resource\n",
    ")\n",
    "\n",
    "def write_dicts_to_jsonl_gz(data, s3_path):\n",
    "    file_as_string = json.dumps(data[0])\n",
    "    for d in data[1:]:\n",
    "        file_as_string += '\\n'\n",
    "        file_as_string += json.dumps(d)\n",
    "    b, k = s3_path_to_bucket_key(s3_path)\n",
    "    compressed_out = gzip.compress(bytes(file_as_string, 'utf-8'))\n",
    "    s3_resource.Object(b, k).put(Body=compressed_out)\n",
    "\n",
    "land_base_path = 's3://mojap-land/open_data/postcodes_example/'\n",
    "\n",
    "s3_out = os.path.join(land_base_path, 'random_postcodes', f'file_land_timestamp={run_timestamp}', f'random_postcodes_{run_timestamp}.jsonl.gz')\n",
    "write_dicts_to_jsonl_gz(data, s3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA SIZE: PASSED (size 10)\n"
     ]
    }
   ],
   "source": [
    "len_data = len(data)\n",
    "if len_data < 10:\n",
    "    error = True\n",
    "    print(f\"TEST DATA SIZE: FAILED (size {len_data})\")\n",
    "else:\n",
    "    print(f\"TEST DATA SIZE: PASSED (size {len_data})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING s3://mojap-land/open_data/postcodes_example/random_postcodes/file_land_timestamp=1655057864/random_postcodes_1655057864.jsonl.gz\n",
      "TEST DATA SIZE: PASSED (size 10)\n",
      "All tests passed!\n",
      "Now writing to raw and deleting from land...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gluejobutils import s3\n",
    "from scripts.utils import (\n",
    "    read_jsonl_from_s3\n",
    ")\n",
    "\n",
    "table_land_path = os.path.join(land_base_path, 'random_postcodes/')\n",
    "\n",
    "error = False\n",
    "meta = pd.read_json('meta_data/raw/random_postcodes.json')\n",
    "colnames = [c['name'] for c in meta['columns']]\n",
    "\n",
    "# Get all partitions then test each one\n",
    "all_data_paths = s3.get_filepaths_from_s3_folder(table_land_path)\n",
    "if len(all_data_paths) == 0:\n",
    "    raise ValueError(f\"Was expecting data in land but nothing was found in the folder: {table_land_path}\")\n",
    "\n",
    "for data_path in all_data_paths:\n",
    "    print(f'TESTING {data_path}')\n",
    "    data = read_jsonl_from_s3(data_path, compressed=True)\n",
    "\n",
    "    # Let's say we always expect at least 100 records\n",
    "    len_data = len(data)\n",
    "    if len_data < 10:\n",
    "        error = True\n",
    "        print(f\"TEST DATA SIZE: FAILED (size {len_data})\")\n",
    "    else:\n",
    "        print(f\"TEST DATA SIZE: PASSED (size {len_data})\")\n",
    "\n",
    "    # We might want to check the data against the our meta data (if we expect all the columns to exist)\n",
    "    # If there is an error wait to test the rest of the data so you can see which other rows fail before raising an error\n",
    "    error_str = ''\n",
    "    for i, row in enumerate(data):\n",
    "        col_mismatch = list(set(row.keys()).symmetric_difference(set(colnames)))\n",
    "        if len(col_mismatch) > 0:\n",
    "            error_str += f\"row {i}: col mismatch: {', '.join(col_mismatch)}\\n\"\n",
    "            error = True\n",
    "\n",
    "    if error_str != '':\n",
    "        print(error_str)\n",
    "\n",
    "    if error:\n",
    "        raise ValueError(\"Raising error due to one of the tests not passing. See log.\")\n",
    "    else:\n",
    "        print(\"All tests passed!\")\n",
    "        print(\"Now writing to raw and deleting from land...\")\n",
    "        raw_hist_out = data_path.replace('s3://mojap-land/', 's3://mojap-raw-hist/')\n",
    "        s3.copy_s3_object(data_path, raw_hist_out)\n",
    "        s3.delete_s3_object(data_path)\n",
    "        print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job \"etl_pipeline_example_job\"...\n",
      "2022-06-12 19:18:42: Job State: RUNNING | Execution Time: 3 (s) | Error: n/a\n",
      "2022-06-12 19:18:52: Job State: RUNNING | Execution Time: 13 (s) | Error: n/a\n",
      "2022-06-12 19:19:03: Job State: RUNNING | Execution Time: 24 (s) | Error: n/a\n",
      "2022-06-12 19:19:13: Job State: RUNNING | Execution Time: 34 (s) | Error: n/a\n",
      "2022-06-12 19:19:23: Job State: RUNNING | Execution Time: 44 (s) | Error: n/a\n",
      "2022-06-12 19:19:34: Job State: RUNNING | Execution Time: 54 (s) | Error: n/a\n",
      "2022-06-12 19:19:44: Job State: RUNNING | Execution Time: 64 (s) | Error: n/a\n",
      "2022-06-12 19:19:54: Job State: RUNNING | Execution Time: 75 (s) | Error: n/a\n",
      "2022-06-12 19:20:04: Job State: RUNNING | Execution Time: 85 (s) | Error: n/a\n",
      "2022-06-12 19:20:14: Job State: RUNNING | Execution Time: 95 (s) | Error: n/a\n",
      "2022-06-12 19:20:24: Job State: SUCCEEDED | Execution Time: 99 (s) | Error: n/a\n"
     ]
    }
   ],
   "source": [
    "from etl_manager.etl import GlueJob\n",
    "import datetime\n",
    "\n",
    "job_bucket = \"alpha-curated-postcodes-example\"\n",
    "iam_role = \"airflow-postcodes-example-role\"\n",
    "github_tag = \"v0.0.1\"\n",
    "snapshot_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Get job parameters for specific glue job\n",
    "job_args = {\"--github_tag\": github_tag, \"--snapshot_date\": snapshot_date}\n",
    "job = GlueJob(f\"etl_pipeline_example_job/\", bucket = job_bucket, job_role = iam_role, job_arguments = job_args)\n",
    "\n",
    "print(f'Starting job \"{job.job_name}\"...')\n",
    "job.run_job()\n",
    "job.wait_for_completion(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl_manager.meta import read_database_folder\n",
    "\n",
    "db = read_database_folder('meta_data/curated/')\n",
    "db.delete_glue_database()\n",
    "db.create_glue_database()\n",
    "\n",
    "db.refresh_all_table_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_postcodes_db random_postcodes\n"
     ]
    }
   ],
   "source": [
    "with open('meta_data/curated/database.json') as f:\n",
    "    database = json.load(f)\n",
    "database_name = database['name']\n",
    "with open('meta_data/curated/random_postcodes.json') as f:\n",
    "    table = json.load(f)\n",
    "table_name = table['name']\n",
    "print(database_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110]]\n"
     ]
    }
   ],
   "source": [
    "import pydbtools as pydb\n",
    "\n",
    "print(pydb.read_sql_query(f\"SELECT COUNT(*) AS Postcodes from {database_name}.{table_name}\").values)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5d0s1r3Y3U6QLe0sy4zmE",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
